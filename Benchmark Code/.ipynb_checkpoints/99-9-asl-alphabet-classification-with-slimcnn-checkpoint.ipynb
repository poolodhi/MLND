{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8e92f87b178b8010aed78bea583433b7b88811ad"
   },
   "source": [
    "I used [\"Interpret Sign Language with Deep Learning\"](https://www.kaggle.com/paultimothymooney/interpret-sign-language-with-deep-learning) code for preprocessing dataset by Paul Mooney, Thanks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4d3a6f308a716b7346984f65bb3d7b67a7d315d6"
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, skimage\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Conv2D, Dense, Dropout, Flatten, Input, Add, GlobalAveragePooling2D, DepthwiseConv2D, BatchNormalization, LeakyReLU\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "imageSize = 64\n",
    "target_dims = (imageSize, imageSize, 3)\n",
    "num_classes = 29\n",
    "\n",
    "train_len = 87000\n",
    "train_dir = \"../Dataset/asl_alphabet_train/asl_alphabet_train/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "28f6e00a91aa646d1c2bd6f6c39c77f6160a7b84",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_data(folder):\n",
    "    \"\"\"\n",
    "    Load the data and labels from the given folder.\n",
    "    \"\"\"\n",
    "    X = np.empty((train_len, imageSize, imageSize, 3), dtype=np.float32)\n",
    "    y = np.empty((train_len,), dtype=np.int)\n",
    "    cnt = 0\n",
    "\n",
    "    for folderName in os.listdir(folder):\n",
    "        if not folderName.startswith('.'):\n",
    "            if folderName in ['A']:\n",
    "                label = 0\n",
    "            elif folderName in ['B']:\n",
    "                label = 1\n",
    "            elif folderName in ['C']:\n",
    "                label = 2\n",
    "            elif folderName in ['D']:\n",
    "                label = 3\n",
    "            elif folderName in ['E']:\n",
    "                label = 4\n",
    "            elif folderName in ['F']:\n",
    "                label = 5\n",
    "            elif folderName in ['G']:\n",
    "                label = 6\n",
    "            elif folderName in ['H']:\n",
    "                label = 7\n",
    "            elif folderName in ['I']:\n",
    "                label = 8\n",
    "            elif folderName in ['J']:\n",
    "                label = 9\n",
    "            elif folderName in ['K']:\n",
    "                label = 10\n",
    "            elif folderName in ['L']:\n",
    "                label = 11\n",
    "            elif folderName in ['M']:\n",
    "                label = 12\n",
    "            elif folderName in ['N']:\n",
    "                label = 13\n",
    "            elif folderName in ['O']:\n",
    "                label = 14\n",
    "            elif folderName in ['P']:\n",
    "                label = 15\n",
    "            elif folderName in ['Q']:\n",
    "                label = 16\n",
    "            elif folderName in ['R']:\n",
    "                label = 17\n",
    "            elif folderName in ['S']:\n",
    "                label = 18\n",
    "            elif folderName in ['T']:\n",
    "                label = 19\n",
    "            elif folderName in ['U']:\n",
    "                label = 20\n",
    "            elif folderName in ['V']:\n",
    "                label = 21\n",
    "            elif folderName in ['W']:\n",
    "                label = 22\n",
    "            elif folderName in ['X']:\n",
    "                label = 23\n",
    "            elif folderName in ['Y']:\n",
    "                label = 24\n",
    "            elif folderName in ['Z']:\n",
    "                label = 25\n",
    "            elif folderName in ['del']:\n",
    "                label = 26\n",
    "            elif folderName in ['nothing']:\n",
    "                label = 27\n",
    "            elif folderName in ['space']:\n",
    "                label = 28           \n",
    "            else:\n",
    "                label = 29\n",
    "            for image_filename in os.listdir(folder + folderName):\n",
    "                img_file = cv2.imread(folder + folderName + '/' + image_filename)\n",
    "                if img_file is not None:\n",
    "                    img_file = skimage.transform.resize(img_file, (imageSize, imageSize, 3))\n",
    "                    img_arr = np.asarray(img_file).reshape((-1, imageSize, imageSize, 3))\n",
    "                    \n",
    "                    X[cnt] = img_arr\n",
    "                    y[cnt] = label\n",
    "                    cnt += 1\n",
    "#                     X.append(img_arr)\n",
    "#                     y.append(label)\n",
    "#     X = np.asarray(X)\n",
    "#     y = np.asarray(y)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHIV\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "C:\\Users\\SHIV\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((78300, 64, 64, 3), (78300, 29), (8700, 64, 64, 3), (8700, 29))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = get_data(train_dir) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1) \n",
    "\n",
    "# Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "y_trainHot = to_categorical(y_train, num_classes=num_classes)\n",
    "y_testHot = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "X_train.shape, y_trainHot.shape, X_test.shape, y_testHot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c596b3cf8e2c68d6e62adf5277da7a1ca9077c6b"
   },
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "932cc8db83f4e84ac816d56110ac28508b8c3c97"
   },
   "outputs": [],
   "source": [
    "train_image_generator = ImageDataGenerator(\n",
    "    samplewise_center=True,\n",
    "    samplewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_image_generator = ImageDataGenerator(\n",
    "    samplewise_center=True,\n",
    "    samplewise_std_normalization=True,\n",
    ")\n",
    "\n",
    "train_generator = train_image_generator.flow(x=X_train, y=y_trainHot, batch_size=batch_size, shuffle=True)\n",
    "val_generator = val_image_generator.flow(x=X_test, y=y_testHot, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9801290b12bff9ca77ef29d860681e413f94497c"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dd77e290cff58996acbbd4f6f75a1c70de37dfc7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=target_dims)\n",
    "net = Conv2D(32, kernel_size=3, strides=1, padding=\"same\")(inputs)\n",
    "net = LeakyReLU()(net)\n",
    "net = Conv2D(32, kernel_size=3, strides=1, padding=\"same\")(net)\n",
    "net = LeakyReLU()(net)\n",
    "net = Conv2D(32, kernel_size=3, strides=2, padding=\"same\")(net)\n",
    "net = LeakyReLU()(net)\n",
    "\n",
    "net = Conv2D(32, kernel_size=3, strides=1, padding=\"same\")(net)\n",
    "net = LeakyReLU()(net)\n",
    "net = Conv2D(32, kernel_size=3, strides=1, padding=\"same\")(net)\n",
    "net = LeakyReLU()(net)\n",
    "net = Conv2D(32, kernel_size=3, strides=2, padding=\"same\")(net)\n",
    "net = LeakyReLU()(net)\n",
    "\n",
    "shortcut = net\n",
    "\n",
    "net = DepthwiseConv2D(kernel_size=3, strides=1, padding='same', kernel_initializer='he_normal')(net)\n",
    "net = BatchNormalization(axis=3)(net)\n",
    "net = LeakyReLU()(net)\n",
    "net = Conv2D(filters=32, kernel_size=1, strides=1, padding='same', kernel_initializer='he_normal')(net)\n",
    "net = BatchNormalization(axis=3)(net)\n",
    "net = LeakyReLU()(net)\n",
    "\n",
    "net = DepthwiseConv2D(kernel_size=3, strides=1, padding='same', kernel_initializer='he_normal')(net)\n",
    "net = BatchNormalization(axis=3)(net)\n",
    "net = LeakyReLU()(net)\n",
    "net = Conv2D(filters=32, kernel_size=1, strides=1, padding='same', kernel_initializer='he_normal')(net)\n",
    "net = BatchNormalization(axis=3)(net)\n",
    "net = LeakyReLU()(net)\n",
    "\n",
    "net = Add()([net, shortcut])\n",
    "\n",
    "net = GlobalAveragePooling2D()(net)\n",
    "net = Dropout(0.2)(net)\n",
    "\n",
    "net = Dense(128, activation='relu')(net)\n",
    "outputs = Dense(num_classes, activation='softmax')(net)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "model.save('/Models/99-model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "16fa58a2542584cc8597564daa8446a04aa92560"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving model from disk...\n",
      "WARNING:tensorflow:From C:\\Users\\SHIV\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\SHIV\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Utils\n",
    "from pathlib import Path\n",
    "from keras.models import load_model, load_weights\n",
    "def load_model_from_disk():\n",
    "    model_file = Path('/Models/99-model.h5')\n",
    "                      \n",
    "    if model_file.is_file():\n",
    "        print('Retrieving model from disk...')\n",
    "        model = load_model(model_file.__str__())\n",
    "        return model\n",
    "    return None\n",
    "\n",
    "model = load_model_from_disk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "b03bce0453b2ae35df51edce38921f74e33c0a95",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1224/1224 [==============================] - 1237s 1s/step - loss: 1.1798 - acc: 0.6002 - val_loss: 0.6868 - val_acc: 0.7289\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.72885, saving model to 2019_02_16_00_46_56-weightcheckpoint.h5\n",
      "Epoch 2/15\n",
      "1224/1224 [==============================] - 1220s 997ms/step - loss: 0.6983 - acc: 0.7570 - val_loss: 0.3068 - val_acc: 0.8924\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.72885 to 0.89241, saving model to 2019_02_16_00_46_56-weightcheckpoint.h5\n",
      "Epoch 3/15\n",
      "1224/1224 [==============================] - 1207s 986ms/step - loss: 0.5162 - acc: 0.8204 - val_loss: 0.2291 - val_acc: 0.9162\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.89241 to 0.91621, saving model to 2019_02_16_00_46_56-weightcheckpoint.h5\n",
      "Epoch 4/15\n",
      "1224/1224 [==============================] - 1196s 977ms/step - loss: 0.4199 - acc: 0.8562 - val_loss: 0.2729 - val_acc: 0.9131\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91621\n",
      "Epoch 5/15\n",
      "1224/1224 [==============================] - 17806s 15s/step - loss: 0.3544 - acc: 0.8802 - val_loss: 0.2623 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91621\n",
      "Epoch 6/15\n",
      "1224/1224 [==============================] - 2291s 2s/step - loss: 0.3059 - acc: 0.8972 - val_loss: 0.1803 - val_acc: 0.9362\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91621 to 0.93621, saving model to 2019_02_16_00_46_56-weightcheckpoint.h5\n",
      "Epoch 7/15\n",
      "1224/1224 [==============================] - 1240s 1s/step - loss: 0.2825 - acc: 0.9049 - val_loss: 0.1411 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.93621 to 0.95207, saving model to 2019_02_16_00_46_56-weightcheckpoint.h5\n",
      "Epoch 8/15\n",
      "1224/1224 [==============================] - 1242s 1s/step - loss: 0.2481 - acc: 0.9174 - val_loss: 0.1395 - val_acc: 0.9520\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95207\n",
      "Epoch 9/15\n",
      "1224/1224 [==============================] - 2087s 2s/step - loss: 0.2300 - acc: 0.9234 - val_loss: 0.1277 - val_acc: 0.9567\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.95207 to 0.95667, saving model to 2019_02_16_00_46_56-weightcheckpoint.h5\n",
      "Epoch 10/15\n",
      "1224/1224 [==============================] - 1245s 1s/step - loss: 0.2158 - acc: 0.9284 - val_loss: 0.0796 - val_acc: 0.9739\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.95667 to 0.97391, saving model to 2019_02_16_00_46_56-weightcheckpoint.h5\n",
      "Epoch 11/15\n",
      "1224/1224 [==============================] - 1254s 1s/step - loss: 0.2025 - acc: 0.9324 - val_loss: 0.1325 - val_acc: 0.9544\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.97391\n",
      "Epoch 12/15\n",
      "1224/1224 [==============================] - 2122s 2s/step - loss: 0.1954 - acc: 0.9354 - val_loss: 0.0495 - val_acc: 0.9837\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.97391 to 0.98368, saving model to 2019_02_16_00_46_56-weightcheckpoint.h5\n",
      "Epoch 13/15\n",
      "1224/1224 [==============================] - 2804s 2s/step - loss: 0.1858 - acc: 0.9386 - val_loss: 0.1140 - val_acc: 0.9647\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.98368\n",
      "Epoch 14/15\n",
      "1224/1224 [==============================] - 1343s 1s/step - loss: 0.1709 - acc: 0.9435 - val_loss: 0.1181 - val_acc: 0.9638\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.98368\n",
      "Epoch 15/15\n",
      "1224/1224 [==============================] - 1412s 1s/step - loss: 0.1745 - acc: 0.9424 - val_loss: 0.0641 - val_acc: 0.9767\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.98368\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "start_time = datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "\n",
    "model.fit_generator(train_generator, epochs=15, validation_data=val_generator,\n",
    "    steps_per_epoch=train_generator.__len__(),\n",
    "    validation_steps=val_generator.__len__(),\n",
    "    callbacks=[\n",
    "        #TensorBoard(log_dir='./logs/%s' % (start_time)),\n",
    "        ModelCheckpoint('%s-weightcheckpoint.h5' % (start_time), monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, verbose=1, mode='auto')\n",
    "])\n",
    "\n",
    "model.save_weights('99-model-weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(folder):\n",
    "    \"\"\"\n",
    "    Load the data and labels from the given folder.\n",
    "    \"\"\"\n",
    "    X = np.empty((28, imageSize, imageSize, 3), dtype=np.float32)\n",
    "    y = np.empty((28,), dtype=np.int)\n",
    "    cnt = 0\n",
    "    \n",
    "    for folderName in os.listdir(folder):\n",
    "        if not folderName.startswith('.'):\n",
    "            if folderName.startswith('A'):\n",
    "                label = 0\n",
    "            elif folderName.startswith('B'):\n",
    "                label = 1\n",
    "            elif folderName.startswith('C'):\n",
    "                label = 2\n",
    "            elif folderName.startswith('D'):\n",
    "                label = 3\n",
    "            elif folderName.startswith('E'):\n",
    "                label = 4\n",
    "            elif folderName.startswith('F'):\n",
    "                label = 5\n",
    "            elif folderName.startswith('G'):\n",
    "                label = 6\n",
    "            elif folderName.startswith('H'):\n",
    "                label = 7\n",
    "            elif folderName.startswith('I'):\n",
    "                label = 8\n",
    "            elif folderName.startswith('J'):\n",
    "                label = 9\n",
    "            elif folderName.startswith('K'):\n",
    "                label = 10\n",
    "            elif folderName.startswith('L'):\n",
    "                label = 11\n",
    "            elif folderName.startswith('M'):\n",
    "                label = 12\n",
    "            elif folderName.startswith('N'):\n",
    "                label = 13\n",
    "            elif folderName.startswith('O'):\n",
    "                label = 14\n",
    "            elif folderName.startswith('P'):\n",
    "                label = 15\n",
    "            elif folderName.startswith('Q'):\n",
    "                label = 16\n",
    "            elif folderName.startswith('R'):\n",
    "                label = 17\n",
    "            elif folderName.startswith('S'):\n",
    "                label = 18\n",
    "            elif folderName.startswith('T'):\n",
    "                label = 19\n",
    "            elif folderName.startswith('U'):\n",
    "                label = 20\n",
    "            elif folderName.startswith('V'):\n",
    "                label = 21\n",
    "            elif folderName.startswith('W'):\n",
    "                label = 22\n",
    "            elif folderName.startswith('X'):\n",
    "                label = 23\n",
    "            elif folderName.startswith('Y'):\n",
    "                label = 24\n",
    "            elif folderName.startswith('Z'):\n",
    "                label = 25\n",
    "            elif folderName.startswith('del'):\n",
    "                label = 26\n",
    "            elif folderName.startswith('nothing'):\n",
    "                label = 27\n",
    "            elif folderName.startswith('space'):\n",
    "                label = 28           \n",
    "            else:\n",
    "                label = 29\n",
    "            img_file = cv2.imread(folderName)\n",
    "            if img_file is not None:\n",
    "                img_file = skimage.transform.resize(img_file, (imageSize, imageSize, 3))\n",
    "                img_arr = np.asarray(img_file).reshape((-1, imageSize, imageSize, 3))\n",
    "                    \n",
    "                X[cnt] = img_arr\n",
    "                y[cnt] = label\n",
    "                cnt += 1\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_uuid": "30c4c68e78bb9d0b80cdf9d7d3b2282ce2fa7ef3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 64, 64, 3), (28, 28))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dir = \"../Dataset/asl_alphabet_test/asl_alphabet_test/\"\n",
    "X_test_real, y_test_real = get_test_data(test_dir)\n",
    "num_classes = 28\n",
    "\n",
    "y_testHot_real = to_categorical(y_test_real, num_classes=num_classes)\n",
    "X_test_real.shape, y_testHot_real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_weights' from 'keras.models' (C:\\Users\\SHIV\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\models.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-f61d9f07fa5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model_from_disk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./Models/99-model-weight.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'load_weights' from 'keras.models' (C:\\Users\\SHIV\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\models.py)"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from keras.models import load_weights\n",
    "\n",
    "model = load_model_from_disk()\n",
    "model.load_weights('./Models/99-model-weight.h5')\n",
    "\n",
    "#Predict\n",
    "y_pred = model.predict(X_test_real)\n",
    "print(y_pred)\n",
    "print(np.argmax(y_pred,axis = 1)) \n",
    "#print('\\n', sklearn.metrics.classification_report(np.where(ytest > 0)[1], np.argmax(y_pred, axis=1), target_names=list(labels.values())), sep='') \n",
    "# Y_pred_classes = np.argmax(y_pred,axis = 1) \n",
    "# Y_pred_classes\n",
    "# Y_true = np.argmax(y_test_real,axis = 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

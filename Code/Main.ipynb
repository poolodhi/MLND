{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASL Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Imports to view data\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "# Visualization\n",
    "from keras.utils import print_summary\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#ML libraries\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directory paths\n",
    "TRAIN_DIR = \"../Dataset/asl_alphabet_train/asl_alphabet_train\"\n",
    "TEST_DIR = \"../Dataset/asl_alphabet_test\"\n",
    "MODEL_DIR = './Model'\n",
    "MODEL_PATH = MODEL_DIR+\"/Model.h5\"\n",
    "MODEL_WEIGHT_PATH = MODEL_DIR+\"/Model_Weight.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global variables\n",
    "TARGET_SIZE = (64, 64)\n",
    "TARGET_DIMS = (64, 64, 3) # add channel for RGB\n",
    "CLASSES = 29\n",
    "VALIDATION_SPLIT = 0.1\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 78300 images belonging to 29 classes.\n",
      "Found 8700 images belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "#Load Train dataset\n",
    "train_image_generator = ImageDataGenerator(\n",
    "    samplewise_center=True,\n",
    "    samplewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=VALIDATION_SPLIT\n",
    ")\n",
    "\n",
    "validation_image_generator = ImageDataGenerator(\n",
    "    samplewise_center=True,\n",
    "    samplewise_std_normalization=True,\n",
    "    validation_split=VALIDATION_SPLIT\n",
    ")\n",
    "\n",
    "train_generator = train_image_generator.flow_from_directory(TRAIN_DIR, target_size=TARGET_SIZE, batch_size=BATCH_SIZE, shuffle=True, subset=\"training\")\n",
    "val_generator = validation_image_generator.flow_from_directory(TRAIN_DIR, target_size=TARGET_SIZE, batch_size=BATCH_SIZE, subset=\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Model\n",
    "\n",
    "def model_build():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=TARGET_DIMS,padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu',padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu',padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu',padding='same'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(128, activation='linear'))\n",
    "    model.add(Dropout(0.2))                  \n",
    "    model.add(Dense(CLASSES, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 8, 8, 64)          73792     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 29)                3741      \n",
      "=================================================================\n",
      "Total params: 179,101\n",
      "Trainable params: 179,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_build()\n",
    "#Compile the model\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "39/39 [==============================] - 36s 924ms/step - loss: 2.8866 - acc: 0.1470 - val_loss: 2.8089 - val_acc: 0.1469\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.80894, saving model to ./Model/Model_Weight.h5\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 37s 957ms/step - loss: 2.7279 - acc: 0.1795 - val_loss: 2.4601 - val_acc: 0.2687\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.80894 to 2.46009, saving model to ./Model/Model_Weight.h5\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 38s 980ms/step - loss: 2.5966 - acc: 0.2135 - val_loss: 2.6455 - val_acc: 0.2219\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.46009\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 38s 965ms/step - loss: 2.4975 - acc: 0.2436 - val_loss: 2.1808 - val_acc: 0.2875\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.46009 to 2.18079, saving model to ./Model/Model_Weight.h5\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 39s 997ms/step - loss: 2.3787 - acc: 0.2644 - val_loss: 2.3858 - val_acc: 0.2781\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.18079\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 39s 993ms/step - loss: 2.3271 - acc: 0.2917 - val_loss: 2.0188 - val_acc: 0.3594\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.18079 to 2.01883, saving model to ./Model/Model_Weight.h5\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - 41s 1s/step - loss: 2.2136 - acc: 0.3089 - val_loss: 1.9569 - val_acc: 0.3531\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.01883 to 1.95692, saving model to ./Model/Model_Weight.h5\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - 39s 1s/step - loss: 2.1274 - acc: 0.3442 - val_loss: 2.0052 - val_acc: 0.3438\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.95692\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - 38s 983ms/step - loss: 2.0551 - acc: 0.3590 - val_loss: 1.6981 - val_acc: 0.4125\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.95692 to 1.69810, saving model to ./Model/Model_Weight.h5\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - 37s 954ms/step - loss: 1.9313 - acc: 0.3922 - val_loss: 1.6102 - val_acc: 0.4656\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.69810 to 1.61024, saving model to ./Model/Model_Weight.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f3fb2de0b8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checkpointer to save the best models\n",
    "checkpointer = ModelCheckpoint(filepath=MODEL_WEIGHT_PATH, \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "steps_per_epoch = int( np.ceil(len(train_generator)*2 / BATCH_SIZE) )\n",
    "validation_steps = int( np.ceil(len(val_generator)*2 / BATCH_SIZE) )\n",
    "\n",
    "model.fit_generator(train_generator, validation_data=val_generator, \n",
    "                    steps_per_epoch =  steps_per_epoch,\n",
    "                    validation_steps = validation_steps,\n",
    "                    epochs=10, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nothing', 'E', 'Q', 'Q', 'Q', 'C', 'del', 'D', 'L', 'P', 'O', 'E', 'D', 'T', 'M', 'C', 'X', 'L', 'J', 'B', 'R', 'T', 'W', 'H', 'L', 'V', 'S', 'T', 'V', 'C', 'W', 'P', 'del', 'D', 'nothing', 'T', 'P', 'S', 'Z', 'E', 'O', 'S', 'D', 'T', 'del', 'X', 'E', 'F', 'nothing', 'Y', 'nothing', 'F', 'W', 'C', 'J', 'F', 'T', 'R', 'D', 'E', 'F', 'Q', 'T', 'E'] 64\n",
      "1.8403854370117188 , 0.421875\n"
     ]
    }
   ],
   "source": [
    "#Predict on validation dataset\n",
    "predictions = model.predict_generator(val_generator, steps=1)        \n",
    "predictions = np.argmax(predictions, axis=-1) #multiple categories\n",
    "label_map = (train_generator.class_indices)\n",
    "label_map = dict((v,k) for k,v in label_map.items()) #flip k,v\n",
    "\n",
    "predictions = [label_map[k] for k in predictions]\n",
    "\n",
    "print(predictions, len(predictions))\n",
    "\n",
    "loss, acc = model.evaluate_generator(val_generator, steps=1, verbose=0)\n",
    "\n",
    "print(loss,\",\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28 images belonging to 1 classes.\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "test_image_generator = ImageDataGenerator(\n",
    "    samplewise_center = True,\n",
    "    samplewise_std_normalization = True,\n",
    ")\n",
    "\n",
    "test_generator = test_image_generator.flow_from_directory(TEST_DIR, target_size=TARGET_SIZE, batch_size=28, shuffle=False, \n",
    "    class_mode='categorical')\n",
    "print(test_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M', 'B', 'C', 'D', 'E', 'F', 'P', 'P', 'R', 'J', 'V', 'L', 'M', 'J', 'O', 'P', 'Q', 'R', 'S', 'J', 'U', 'V', 'W', 'X', 'T', 'Y', 'nothing', 'space'] 28\n"
     ]
    }
   ],
   "source": [
    "#Predict\n",
    "test_generator.reset()\n",
    "predictions = model.predict_generator(test_generator, steps=1)\n",
    "predictions = np.argmax(predictions, axis=1) #multiple categories\n",
    "label_map = (train_generator.class_indices)\n",
    "label_map = dict((v,k) for k,v in label_map.items()) #flip k,v\n",
    "\n",
    "predictions = [label_map[k] for k in predictions]\n",
    "\n",
    "print(predictions, len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Filename Predictions\n",
      "0         asl_alphabet_test\\A_test.jpg           M\n",
      "1         asl_alphabet_test\\B_test.jpg           B\n",
      "2         asl_alphabet_test\\C_test.jpg           C\n",
      "3         asl_alphabet_test\\D_test.jpg           D\n",
      "4         asl_alphabet_test\\E_test.jpg           E\n",
      "5         asl_alphabet_test\\F_test.jpg           F\n",
      "6         asl_alphabet_test\\G_test.jpg           P\n",
      "7         asl_alphabet_test\\H_test.jpg           P\n",
      "8         asl_alphabet_test\\I_test.jpg           R\n",
      "9         asl_alphabet_test\\J_test.jpg           J\n",
      "10        asl_alphabet_test\\K_test.jpg           V\n",
      "11        asl_alphabet_test\\L_test.jpg           L\n",
      "12        asl_alphabet_test\\M_test.jpg           M\n",
      "13        asl_alphabet_test\\N_test.jpg           J\n",
      "14        asl_alphabet_test\\O_test.jpg           O\n",
      "15        asl_alphabet_test\\P_test.jpg           P\n",
      "16        asl_alphabet_test\\Q_test.jpg           Q\n",
      "17        asl_alphabet_test\\R_test.jpg           R\n",
      "18        asl_alphabet_test\\S_test.jpg           S\n",
      "19        asl_alphabet_test\\T_test.jpg           J\n",
      "20        asl_alphabet_test\\U_test.jpg           U\n",
      "21        asl_alphabet_test\\V_test.jpg           V\n",
      "22        asl_alphabet_test\\W_test.jpg           W\n",
      "23        asl_alphabet_test\\X_test.jpg           X\n",
      "24        asl_alphabet_test\\Y_test.jpg           T\n",
      "25        asl_alphabet_test\\Z_test.jpg           Y\n",
      "26  asl_alphabet_test\\nothing_test.jpg     nothing\n",
      "27    asl_alphabet_test\\space_test.jpg       space\n"
     ]
    }
   ],
   "source": [
    "filenames=test_generator.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 67.85714285714286\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for file,prediction in zip(filenames,predictions):\n",
    "    #print(file,prediction)\n",
    "    if(prediction+'_test' in file):\n",
    "        count+=1\n",
    "        \n",
    "print(\"accuracy\",count/len(filenames)*100)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
